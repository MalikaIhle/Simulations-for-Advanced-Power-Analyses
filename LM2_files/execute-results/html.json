{
  "hash": "4f9f32242df862e6d9b152e180e0aba7",
  "result": {
    "markdown": "---\ntitle: \"Linear Model 2: Multiple predictors\"\nauthor: \"Felix Schönbrodt\"\nexecute:\n  cache: true\n---\n\n::: {.cell hash='LM2_cache/html/unnamed-chunk-1_86c67f1ac5d969fbad44855aac35fe38'}\n\n```{.r .cell-code}\n# TODO: collect the installation of all necessary packages in one place at the beginning of the tutorial\n\n#install.packages(c(\"ggplot2\", \"ggdist\", \"pwr\", \"MBESS\"))\n```\n:::\n\n\nIn the [first chapter on linear models](LM1.qmd), we had the simplest possible linear model: a continuous outcome variable is predicted by a single dichotomous predictor. In this chapter, we build up increasingly complex models by (a) adding a single continuous predictor and (b) modeling an interaction.\n\n# Adding a continuous predictor\n\nWe can improve our causal inference by including the pre-treatment baseline scores of depression into the model: This way, participants are \"their own control group\" and we can explain a lot of (formerly) unexplained error variance by\n\n::: {.callout-note}\nMany statistical models have been proposed for analyzing a pre-post control-treatment design. There is growing consensus that a model with the baseline (pre) measurement as covariate is the most appropriate (https://bmcmedresmethodol.biomedcentral.com/articles/10.1186/s12874-021-01323-9; Senn, S. (2006). Change from baseline and analysis of covariance revisited. Statistics in Medicine, 25(24), 4334–4344. https://doi.org/10.1002/sim.2682).\n:::\n\nThe raw effect size stays the same - the treatment still is expected to lead to a 6-point decrease in depression scores on average. But \n\n## Get some real data as starting point\n\nThe \"Beat the blues\" (`BtheB`) data set from the `HSAUR` R package contains pre-treatment baseline values (`bdi.pre`), along with multiple post-treatment values. Here we focus on the first post-treatment assessment, 2 months after the treatment (`bdi.2m`).\n\n\n::: {.cell hash='LM2_cache/html/unnamed-chunk-2_52c03ef235720c8ffae05ed21ade43a3'}\n\n```{.r .cell-code}\n# load the data\ndata(\"BtheB\", package = \"HSAUR\")\n\n# center the BDI baseline \n# (for better interpretability of the coefficient)\nBtheB$bdi.pre.c <- BtheB$bdi.pre - mean(BtheB$bdi.pre)\n\nl0 <- lm(bdi.2m ~ treatment, data=BtheB)\nsummary(l0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = bdi.2m ~ treatment, data = BtheB)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-19.467  -7.712  -1.712   7.288  28.533 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)      19.467      1.576  12.349   <2e-16 ***\ntreatmentBtheB   -4.755      2.153  -2.209   0.0296 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 10.57 on 95 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.04884,\tAdjusted R-squared:  0.03882 \nF-statistic: 4.878 on 1 and 95 DF,  p-value: 0.02961\n```\n:::\n\n```{.r .cell-code}\n# res_var = 10.57^2 = 112\n\nl1 <- lm(bdi.2m ~ bdi.pre.c + treatment, data=BtheB)\nsummary(l1)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = bdi.2m ~ bdi.pre.c + treatment, data = BtheB)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-26.1789  -4.3869   0.2449   4.7610  24.2327 \n\nCoefficients:\n               Estimate Std. Error t value Pr(>|t|)    \n(Intercept)    19.14311    1.24792  15.340  < 2e-16 ***\nbdi.pre.c       0.60289    0.07932   7.601 2.17e-11 ***\ntreatmentBtheB -3.95436    1.70666  -2.317   0.0227 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 8.366 on 94 degrees of freedom\n  (3 observations deleted due to missingness)\nMultiple R-squared:  0.4109,\tAdjusted R-squared:  0.3984 \nF-statistic: 32.78 on 2 and 94 DF,  p-value: 1.579e-11\n```\n:::\n\n```{.r .cell-code}\n# res_var = 8.366^2 = 70\n\ncor(BtheB$bdi.pre, BtheB$bdi.2m, use=\"p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6142207\n```\n:::\n\n```{.r .cell-code}\ncov(BtheB$bdi.pre, BtheB$bdi.2m, use=\"p\")\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 71.4608\n```\n:::\n\n```{.r .cell-code}\n# cor_var = 0.614^2 = 38%\n```\n:::\n\n\nTODO: Explain how we got to the reduction of the error term!\n\nWe assume (a) independence of both predictor variables. This is plausible, because the treatment was randomized.\nThe pre-measurement explains 38% of the variance in the post-measurement. As this variane is unrelated to the treatment factor, it reduces the error term by 38%:\n\n$var_{err} = 117 * (1-0.38) = 72.54$\n\nThis is our new estimate of the error term.\n\n## Doing the power analysis\n\nWe again use the `replicate` function to repeatedly call the `sim` function for 1000 iterations.\n\n\n::: {.cell hash='LM2_cache/html/unnamed-chunk-3_0495fd3fd49653c3d21ed86f1e7295c8'}\n\n```{.r .cell-code}\nset.seed(0xBEEF)\n\nsim <- function(n=100, treatment_effect=-6, prepost_effect = 0.6) {\n  \n  # define/simulate all predictor variables\n  treatment <- c(rep(0, n/2), rep(1, n/2))\n  BDI_pre.c <- rnorm(n, mean=23, sd=sqrt(117))\n  \n  # CHANGEs (compared to chapter 1):\n  # - Add the covariate as continuous predictor\n  # - Reduce the SD of the error term from sqrt(117) to sqrt(72)\n  BDI_post <- \n    23 +                          # intercept\n    prepost_effect*BDI_pre.c +    # covariate (baseline)\n    treatment_effect*treatment +  # treatment effect\n    rnorm(n, mean=0, sd=sqrt(72)) # error term\n  \n  res <- lm(BDI_post ~ BDI_pre.c + treatment)\n  p_value <- summary(res)$coefficients[\"treatment\", \"Pr(>|t|)\"]\n  return(p_value)\n}\n\n\n# define all predictor and simulation variables.\niterations <- 2000\nns <- seq(90, 130, by=4) # ns are already adjusted to the relevant range\n\nresult <- data.frame()\n\nfor (n in ns) {  # loop through elements of the vector \"ns\"\n  p_values <- replicate(iterations, sim(n=n))\n  \n  result <- rbind(result, data.frame(\n      n = n,\n      power = sum(p_values < .005)/iterations\n    )\n  )\n  \n  # show the result after each run (not shown here in the tutorial)\n  print(result)\n}\n```\n:::\n\n\nIn the original analysis, we needed n=180 (90 in each group) for 80% power. Including the baseline covariate (which explains $r^2 = .61^2 = 37%$ of the variance in post scores) reduces that number to n=112.\n\nLet's check the plausibility of our power simulation. Borm et al ([2007](http://www.math.chalmers.se/Stat/Grundutb/GU/MSA620/S18/Ancova.pdf), p. 1237) propose a simple method how to arrive at a planned sample size when switching from a simple t-test (comparing post-treatment groups) to a model that controls for the baseline:\n\n> \"We propose a simple method for the sample size calculation when ANCOVA is used: multiply the number of subjects required for the t-test by (1-r2) and add one extra subject per group.\n\nWhen we enter our assumed pre-post-correlation into that formula, we arrive a n=115 - very close to our value:\n$$180 * (1 - .61^2) + 2 = 115$$\n\n# Modeling an interaction\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}