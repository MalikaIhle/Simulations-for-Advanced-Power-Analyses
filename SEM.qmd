---
title: "Structural Equation Models (SEM)"
format: html
author: Moritz Fischer
execute:
  cache: true
---

```{r install packages, message=FALSE, warning=FALSE}
#install.packages(c("lavaan", "ggplot2", "MASS", "apaTables", "MBESS"), dependencies = TRUE)

library("lavaan")
library("MASS")
library("ggplot2")
library("dplyr")
library("MBESS")
```

In this chapter, we will focus on a few rather simple Structural Equation Models (SEM). The goal is to illustrate how simulations can be used to estimate statistical power to detect a given effect in a SEM. In the context of SEMs, the focal effect may be for instance a fit index (e.g., Chi-Square, RMSEA, etc.) or a model coefficient (e.g., a regression coefficient for the association between two latent factors). In this chapter, we  only focus on the latter, that is, power analyses for regression coefficients in the context of SEM. Please see the bonus chapter titled "XXX" if you're interested in power analyses for fit indices.

# A simulation-based power analysis for a single regression coefficient between latent variables

Let's consider the following example: We are planning to conduct a study investigating whether openness to experience (as conceptualized in the big five) relates negatively to generalized prejudice, that is a latent variable comprising prejudice towards different social groups (e.g., women, foreigners, homosexuals, disabled people). We could plan to scrutinize this prediction with a SEM in which both openness to experience and generalized prejudice are modelled as latent variables. 

::: {.callout-note}

Please note that the predictions used as examples in this chapter are not necessarily theoretically meaningful hypotheses. They were also not formulated a-priori. We merely use them to illustrate the mechanics of simulation-based power analyses in the context of SEM.

:::


## Let's get some real data as starting point

Just like for any other simulation-based power analysis, we first need to come up with plausible estimates of the distribution of the (manifest) variables. For the sake of simplicity, let's assume that there is a published study that measured manifestations of our two latent variables and that the corresponding data set is publicly available. For the purpose of this tutorial, we will draw on a publication by Bergh et al (2016) and the corresponding data set which has been made accessible as part of the `MPsychoR` package. Let's take a look at this data set.


```{r load data, message=FALSE}

#install.packages("MPsychoR")
library(MPsychoR)
data("Bergh")

#let's take a look
head(Bergh)
tail(Bergh)

```

This data set comprises `r ncol(Bergh)` variables measured in `r nrow(Bergh)` participants. For now, we will focus on the following measured variables: 

-   `EP` is a continuous variable measuring ethnic prejudice. 
-   `SP` is a continuous variable measuring sexism. 
-   `HP` is a continuous variable measuring sexual prejudice towards gays and lesbians. 
-   `DP` is a continuous variable measuring prejudice toward mentally people with disabilities. 
-   `O1`, `O2`, and `O3` are three items measuring openness to experience.

To get an impression of this data, we can inspect means, standard deviations, and correlations of 
the variables we're interested in. I am using the `attach` function which makes it easier to access variables of this data set throughout this tutorial without specifying the data set containing this variable again and again. 

```{r correlations SEM}

attach(Bergh)
apaTables::apa.cor.table(cbind(EP, SP, HP, DP, O1, O2, O3))
detach(Bergh)

```

As we have discussed in the previous chapters, the starting point of every simulation-based power analysis is to specify the population parameters of the variables of interest. With these population parameters, we can then simulate data, for example using the `mrvnorm` function from the `MASS` package. In our example, we can estimate the population parameters from the study by Bergh et al. (2016). We start by calculating the means of the  variables, rounding them generously, and storing them in a vector called `means_vector`. 

```{r mean vector SEM}

attach(Bergh)

#store means
means_vector <- c(mean(EP), mean(SP), mean(HP), mean(DP), mean(O1), mean(O2), mean(O3)) |> round(2)

#Let's take a look
means_vector

detach(Bergh)

```

We also need the variance-covariance matrix of our variables in order to simulate data. Luckily, we can estimate this from the Bergh et al. data as well. There are two ways to do this. First, we can use the `cov` function to obtain the variance-covariance matrix. This matrix incorporates the variance of each variable on the diagonal, and the covariances in the remaining cells. 

```{r cov matrix SEM}

attach(Bergh)

#store covariances
cov_mat <- cov(cbind(EP, SP, HP, DP, O1, O2, O3)) |> round(2)

#Let's take a look
cov_mat

detach(Bergh)

```

This works well as long as we have a data set (e.g., from a pilot study or published work) to estimate the variances and covariances. In other cases, however, we might not have access to such a data set. In this case, we might only have a correlation table that was provided in a published paper. But that's no problem either, we can simply transform the correlations and standard deviations of the variables of interest into a variance-covariance matrix. The following chunk shows how this works by using the `cor2cov` function from the `MBESS` package. 

```{r sd vector and correlations SEM}

attach(Bergh)

#store correlation matrix 
cor_mat <- cor(cbind(EP, SP, HP, DP, O1, O2, O3)) 

#store standard deviations
sd_vector <- c(sd(EP), sd(SP), sd(HP), sd(DP), sd(O1), sd(O2), sd(O3))

#transform correlations and standard deviations into variance-covariance matrix
cov_mat2 <- MBESS::cor2cov(cor.mat = cor_mat, sd = sd_vector) |> as.data.frame() |> round(2)

#Let's take a look
cov_mat2

detach(Bergh)

```

Let's do a plausibility check: Did the two ways to estimate the variance-covariance matrix lead to the same results?

```{r plausibility check SEM}

cov_mat == cov_mat2

```

Indeed, this worked! Both procedures lead to the exact same variance-covariance matrix. Now that we have an approximation of the variance-covariance matrix, we use the `mvrnorm` function from the `MASS` package to simulate data from a multivariate normal distribution. The following code simulates `n = 50` observations from the specified population. 

```{r simulate data SEM}

#Set seed to make results reproducible
set.seed(21364)

#simulate data
my_first_simulated_data <- MASS::mvrnorm(n = 50, mu=means_vector, Sigma = cov_mat) |> as.data.frame()

#Let's take a look
head(my_first_simulated_data)

```

We could now fit a SEM to this simulated data set and check whether the regression coefficient modelling the association between openness to experience and generalized prejudice is significant at an $\alpha$-level of .005.

```{r analyze data SEM}

#specify SEM
model_sem <- "generalized_prejudice =~ EP + DP + SP + HP
              openness =~ O1 + O2 + O3
              generalized_prejudice ~ openness"

#fit the SEM to the simulated data set
fit_sem <- sem(model_sem, data = my_first_simulated_data)

#display the results
summary(fit_sem)

# TODO: How can we enter stnadardized regression coefficients?
#model_sem_stand <- "generalized_prejudice =~ EP + DP + SP + HP
#                  agreeableness =~ A1 + A2 + A3
#                  generalized_prejudice ~ agreeableness
#              "
#fit_sem_stand <- cfa(model_sem_stand, data = Bergh, std.lv=TRUE)
#summary(fit_sem_stand, standardized=TRUE)



```

The results show that in this case, the regression coefficient is `r lavaan::parameterestimates(fit_sem)[8,]$est |> round(2)` which is significant with p = `r lavaan::parameterestimates(fit_sem)[8,]$pvalue |> round(3)`. But, actually, it is not our primary interest to see whether this particular simulated data set results in an acceptable model fit. Rather, we want to know how many of a theoretically infinite number of simulations yield a significant p-value of this parameter. Thus, as in the previous chapters, we now repeatedly simulate data sets of a certain size (say, 50 observations) from the specified population and store the results of the focal test (here: the p-value of the regression coefficient) in a vector called `p_values`. 

```{r multiple iterations SEM, warning=FALSE}

#let's do 1000 iterations
iterations <- 1000

#prepare an empty NA vector with 1000 slots
p_values <- rep(NA, iterations)

#sample size per iteration
n <- 50


#simulate data
for(i in 1:iterations){

  simulated_data <- MASS::mvrnorm(n = n, mu = means_vector, Sigma = cov_mat) |> as.data.frame()
  fit_sem_simulated <- sem(model_sem, data = simulated_data)
  
  p_values[i] <- parameterestimates(fit_sem_simulated)[8,]$pvalue
  
}

```

How many of our 1000 virtual samples would have found a significant p-value (i.e., p < .005)?

```{r results SEM}

#frequency table
table(p_values < .005)

#percentage of significant results
sum(p_values < .005)/iterations*100

```

Only `r round(sum(p_values < .005)*100/iterations)`% of samples with the same size of $n=50$ result in a significant p-value. We conclude that $n=50$ observations seems to be insufficient, as the power with these parameters is lower than 80%. 

## Sample size planning: Find the necessary sample size

But how many observations do we need to find the presumed effect with a power of 80%? Like before, we can now systematically vary certain parameters (e.g., sample size) of our simulation and see how that affects power. We could, for example, vary the sample size in a range from 50 to 200. Running these simulations typically requires quite some time for your computer.


```{r power analysis SEM, warning=FALSE, cache=TRUE}

#test ns between 50 and 200
ns_sem <- seq(50, 200, by=10) 

#prepare empty vector to store results
result_sem <- data.frame()

#set number of iterations
iterations_sem <- 1000

#write function
sim_sem <- function(n, model, mu, Sigma) {
  

  simulated_data <- MASS::mvrnorm(n = n, mu = mu, Sigma = Sigma) |> as.data.frame()
  fit_sem_simulated <- sem(model_sem, data = simulated_data)
  p_value_sem <- parameterestimates(fit_sem_simulated)[8,]$pvalue
  return(p_value_sem)
  
    }


#replicate function with varying ns
for (n in ns_sem) {  
  
p_values_sem <- replicate(iterations_sem, sim_sem(n = n, model = model_mediation, mu = means_vector, Sigma = cov_mat))  
result_sem <- rbind(result_sem, data.frame(
    n = n,
    power = sum(p_values_sem < .005)/iterations_sem)
  )

}

```

Let's plot the results:

```{r plot power curve SEM}

ggplot(result_sem, aes(x=n, y=power)) + geom_point() + geom_line() + scale_x_continuous(n.breaks = 10) + geom_hline(yintercept= 0.8, color = "red")

```

This graph suggests that we need a sample size of approximately 58 to reach a power of 80% with the given population estimates. 

# A simulation-based power analysis for a mediation model with latent variables

Sometimes, researchers not only wish to investigate whether and how two (latent) variables related to each other, but rather whether the association between two (manifest or latent) variables is mediated by a third variable. We will run a power analysis for such a latent mediation model in the following. To this end, we assume that we were interested in whether a potential effect of gender on generalized prejudice is (fully or partially) mediated by openness to experience. Fortunately, the data set by Bergh et al (2016) also contains a gender variable. We can therefore repeat the same steps as in our previous power analysis, but only incorporate gender into our analysis. Specifically, this means that we will follow these steps:

1. find plausible estimates of the population parameters
2. specify the statistical model
3. simulate data from this population
4. compute the index of interest (e.g., the p-value) and store the results
5. repeat steps 2) and 3) multiple times
6. count how many samples would have detected the specified effect (i.e., compute the statistical power)
7. vary your simulation parameters until the desired level of power (e.g., 80%) is achieved

Therefore, we first draw on the Bergh et al (2016) data set to estimate the means and the variance-covariance matrix. In this data set, gender is a factor with two levels, male and female. In order to be able to calculate with this variable, we first need to transform it into an integer variable, for instance coding male = 0 and female = 1. 

```{r means and cov mediation}

Bergh_int <- Bergh 
Bergh_int$gender <- ifelse(Bergh_int$gender == "male", 0, ifelse(Bergh_int$gender == "female", 1, NA))


attach(Bergh_int)

#store means
means_mediation <- c(mean(gender), mean(EP), mean(SP), mean(HP), mean(DP), mean(O1), mean(O2), mean(O3)) |> round(2)

#store covarainces
cov_mediation <- cov(cbind(gender, EP, SP, HP, DP, O1, O2, O3)) |> round(2)


```

Referring two step #2, now specify the statistical mediation model in lavaan. 

```{r specify mediation model}

#specify mediation model
model_mediation <- '

              # measurement model
              generalized_prejudice =~ EP + DP + SP + HP
              openness =~ O1 + O2 + O3
              
              # direct effect
              generalized_prejudice ~ c*gender
              
              # mediator
              openness ~ a*gender
              generalized_prejudice ~ b*openness


              # indirect effect (a*b)
              ab := a*b
           
              # total effect
              total := c + (a*b)

'

```

To verify that this model syntax works properly, we can fit this model to the data set provided by Bergh et al. (2016).

```{r test mediation model with the pilot data}

#fit the SEM to the simulated data set
fit_mediation <- sem(model_mediation, data = Bergh_int)

#display the results
summary(fit_mediation)

```

Now, everything is set up to run the actual power analysis. In the following chunk, we repeatedly simulate data from the specified population and store the p-value of the indirect effect while varying the sample size in a range from 100 to 1500. 

```{r simulate data mediation, cache=TRUE}
  
#set seed
set.seed(56465)

#test ns between 100 and 1500
ns_mediation <- seq(100, 1500, by=20) 

#prepare empty vector to store results
result_mediation <- data.frame()

#iterations
iterations_mediation <- 1000

#write function
sim_mediation <- function(n, model, mu, Sigma) {
  

      simulated_data_mediation <- MASS::mvrnorm(n = n, mu = mu, Sigma = Sigma) |> as.data.frame()
      fit_mediation_simulated <- sem(model_mediation, data = simulated_data_mediation)
  
      p_value_mediation <- parameterestimates(fit_mediation_simulated)[21,]$pvalue
      return(p_value_mediation)
    }


#replicate function with varying ns
for (n in ns_mediation) {  
  
p_values_mediation <- replicate(iterations_mediation, sim_mediation(n = n, model = model_mediation, mu = means_mediation, Sigma = cov_mediation))  
result_mediation <- rbind(result_mediation, data.frame(
    n = n,
    power = sum(p_values_mediation < .005)/iterations_mediation)
  )

}
```

Let's plot the results:

```{r plot power curve mediation}

ggplot(result_mediation, aes(x=n, y=power)) + geom_point() + geom_line() + scale_y_continuous(n.breaks = 10) + scale_x_continuous(n.breaks = 20) + geom_hline(yintercept= 0.8, color = "red")

```

As shown, roughly 1,350 participants will be needed to obtain sufficient power under the assumptions we specified.

# References

Bergh, R., Akrami, N., Sidanius, J., & Sibley, C. G. (2016). Is group membership necessary for understanding generalized prejudice? A re-evaluation of why prejudices are interrelated. Journal of Personality and Social Psychology, 111(3), 367–395. https://doi.org/10.1037/pspi0000064

Wang, Y. A., & Rhemtulla, M. (2021). Power analysis for parameter estimation in structural equation modeling: A discussion and tutorial. Advances in Methods and Practices in Psychological Science, 4(1), 1–17. https://doi.org/10.1177/2515245920918253

