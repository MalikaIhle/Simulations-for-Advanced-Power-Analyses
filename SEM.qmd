---
title: "Structural Equation Models (SEM)"
format: html
author: Moritz Fischer
execute:
  cache: true
---

```{r install packages, message=FALSE, warning=FALSE}
#install.packages(c("lavaan", "ggplot2", "MASS", "apaTables", "MBESS", "semPlot"), dependencies = TRUE)

library("lavaan")
library("MASS")
library("ggplot2")
library("dplyr")
library("MBESS")
```

In this chapter, we will focus on a few rather simple Structural Equation Models (SEM). The goal is to illustrate how simulations can be used to estimate statistical power to detect a given effect in a SEM. In the context of SEMs, the focal effect may be for instance a fit index (e.g., Chi-Square, RMSEA, etc.) or a model coefficient (e.g., a regression coefficient for the association between two latent factors). In this chapter, we  only focus on the latter, that is, power analyses for regression coefficients in the context of SEM. Please read the bonus chapter titled "XXX" if you're interested in power analyses for fit indices.

# A simulation-based power analysis for a single regression coefficient between latent variables

Let's consider the following example: We are planning to conduct a study investigating whether Big Five openness to experience relates negatively to generalized prejudice, that is a latent variable comprising prejudice towards different social groups (e.g., women, foreigners, homosexuals, disabled people). We could plan to scrutinize this prediction with a SEM in which both openness to experience and generalized prejudice are conceptualized as latent variables. 

::: {.callout-note}

Please note that the predictions used as examples in this chapter are not necessarily theoretically-meaningful or interesting hypotheses. They were also not formulated a-priori. We merely use them to illustrate the mechanics of simulation-based power analyses.

:::


## Let's get some real data as starting point

Just like for any other simulation-based power analysis, we first need to come up with plausible estimates of the distribution of the (manifest) variables. For the sake of simplicity, let's assume that there is a published study that measured manifestations of our two latent variables and that the corresponding data set is publicly available. For the purpose of this tutorial, we will draw on a publication by Bergh et al (2016) and the corresponding data set which has been made accessible as part of the `MPsychoR` package. Let's take a look at this data set.


```{r load data, message=FALSE}

#install.packages("MPsychoR")
library(MPsychoR)
data("Bergh")

#let's take a look
head(Bergh)
tail(Bergh)

```

This data set comprises 11 variables measured in 861 participants. For now, we will focus on the following measured variables: 

-   `EP` is a continuous variable measuring ethnic prejudice. 
-   `SP` is a continuous variable measuring sexism. 
-   `HP` is a continuous variable measuring sexual prejudice towards gays and lesbians. 
-   `DP` is a continuous variable measuring prejudice toward mentally people with disabilities. 
-   `O1`, `O2`, and `O3` are three items measuring openness to experience.

To get an impression of this data, we can inspect means, standard deviations, and correlations of 
the variables we're interested in. I am using the `attach` function which makes it easier to access variables of this data set throughout this tutorial without specifying the data set containing this variable again and again. 

```{r correlations}

attach(Bergh)
apaTables::apa.cor.table(cbind(EP, SP, HP, DP, O1, O2, O3))

```

As we have discussed in the previous chapters, the starting point of every simulation-based power analysis is to specify the population parameters of the variables of interest. With these population parameters, we can then simulate data, for example using the `mrvnorm` function from the `MASS` package. In our example, we can estimate the population parameters from the study by Bergh et al. (2016). We start by calculating the means of the  variables, rounding them generously, and storing them in a vector called `means_vector`. 

```{r mean vector}

means_vector <- c(mean(EP), mean(SP), mean(HP), mean(DP), mean(O1), mean(O2), mean(O3)) |> round(2)

#Let's take a look
means_vector


```

We also need the variance-covariance matrix of our variables in order to simulate data. Luckily, we can estimate this from the Bergh et al. data as well. There are two ways to do this. First, we can use the `cov` function to obtain the variance-covariance matrix. This matrix has the variance of each variable on the diagonal, and the covariances in the remaining cells. We also round the estimates as in the previous step.   

```{r cov matrix}

cov_mat <- cov(cbind(EP, SP, HP, DP, O1, O2, O3)) |> round(2)

#Let's take a look
cov_mat

```

This works well, as long as I have a data set (e.g., from a pilot study or published work) to estimate the variances and covariances. In other cases, however, I might not have access to such a data set but maybe only to a correlation table that was provided in a published paper. But that's no problem either, I can simply transform the correlations and standard deviations of the variables of interest into a variance-covariance matrix. The following chunk shows how this works by using the `cor2cov` function from the `MBESS` package. 

```{r sd vector and correlations}

#store correlation matrix 
cor_mat <- cor(cbind(EP, SP, HP, DP, O1, O2, O3)) 

#store standard deviations
sd_vector <- c(sd(EP), sd(SP), sd(HP), sd(DP), sd(O1), sd(O2), sd(O3))

#transform correlations and standard deviations into variance-covariance matrix
cov_mat2 <- MBESS::cor2cov(cor.mat = cor_mat, sd = sd_vector) |> as.data.frame() |> round(2)

#Let's take a look
cov_mat2

```


Let's do a plausibility check: Did the two ways to estimate the variance-covariance matrix lead to the same results?

```{r plausibility check}

cov_mat == cov_mat2

```

Indeed, this worked! Both procedures lead to the exact same variance-covariance matrix. Now that we have an approximation of the variance-covariance matrix, we use the `mvrnorm` function in the `MASS` package to simulate data from a multivariate normal distribution. The following code simulates `n = 50` observations from the specified population. 

```{r simulate data}

#Set seed to make results reproducible
set.seed(21364)

simulated_data <- MASS::mvrnorm(n = 50, mu=means_vector, Sigma = cov_mat) |> as.data.frame()

head(simulated_data)

```

We could now fit a SEM to this simulated data set and check whether the regression coefficient modelling the association between openness to experience and generalized prejudice is significant at an $\alpha$-level of .005.

```{r analyze data}

model_sem <- "generalized_prejudice =~ EP + DP + SP + HP
              openness =~ O1 + O2 + O3
              generalized_prejudice ~ openness"

fit_sem <- cfa(model_sem, data = simulated_data)
summary(fit_sem)

# TODO: How can we enter stnadardized regression coefficients?
#model_sem_stand <- "generalized_prejudice =~ EP + DP + SP + HP
#                  agreeableness =~ A1 + A2 + A3
#                  generalized_prejudice ~ agreeableness
#              "
#fit_sem_stand <- cfa(model_sem_stand, data = Bergh, std.lv=TRUE)
#summary(fit_sem_stand, standardized=TRUE)



```

Let's visualize the results for a better overview.

```{r graphic}

semPlot::semPaths(fit_sem, layout = "circle2", whatLabels = "est", sizeMan = 5 , sizeLat = 8)

```



The results show that in this case, the regression coefficient is `r lavaan::parameterestimates(fit_sem)[8,]$est` which is significant with p = `r lavaan::parameterestimates(fit_sem)[8,]$pvalue` and thus significant. But, actually, it is not our primary interest to see whether this particular simulated data set results in an acceptable model fit. Rather, we want to know how many of a theoretically infinite number of simulations yield a significant p-value of this parameter. Thus, as in the previous chapters, we now repeatedly simulate data sets of a certain size (say, 100 observations) from the specified population and store the results of the focal test (here: the p-value of the regression coefficient) in a vector called `p_values`. 

```{r multiple iterations cfa, warning=FALSE}

#Let's do 1000 iterations
iterations <- 1000

#Prepare an empty NA vector with 1000 slots
p_values <- rep(NA, iterations)

#Sample size per iteration
n <- 50

for(i in 1:iterations){

  simulated_data <- MASS::mvrnorm(n = n, mu = means_vector, Sigma = cov_mat) |> as.data.frame()
  fit_sem_simulated <- sem(model_sem, data = simulated_data)
  
  p_values[i] <- parameterestimates(fit_sem_simulated)[8,]$pvalue
  
}

```

How many of our 1000 virtual samples would have found a significant p-value (i.e., p < .005)?

```{r results sem}

table(p_values < .005)

```

Only `r round(sum(p_values < .005)*100/iterations)`% of samples with the same size of $n=50$ result in a significant p-value. We conclude that $n=100$ observations seems to be insufficient, as the power with these parameters is lower than 80%. 

## Sample size planning: Find the necessary sample size

But how many observations do we need to find the presumed effect with a power of 80%? Like before, we can now systematically vary certain parameters (e.g., sample size) of our simulation and see how that affects power. We could, for example, vary the sample size in a range from 50 to 200. Running these simulations typically requires quite some time for your computer.


```{r power analysis cfa, warning=FALSE}

ns <- seq(50, 200, by=10) # test ns between 50 and 200

#prepare empty vector to store results
result <- data.frame()

for (n in ns){  # outer loop
  
  p_values <- rep(NA, iterations)
  iterations <- 1000
  
#prepare an empty NA vector with 1000 slots
p_values <- rep(NA, iterations)

for(i in 1:iterations){

  simulated_data <- MASS::mvrnorm(n = n, mu = means_vector, Sigma = cov_mat) |> as.data.frame()
  fit_sem_simulated <- sem(model_sem, data = simulated_data)
  
  p_values[i] <- parameterestimates(fit_sem_simulated)[8,]$pvalue
  
}


  result <- rbind(result, data.frame(
    n = n,
    power = sum(p_values < .005)/iterations)
  )
  
}

```

Let's plot there result:

```{r plot cfa}

ggplot(result, aes(x=n, y=power)) + geom_point() + geom_line() + scale_y_continuous(n.breaks = 10) + scale_x_continuous(n.breaks = 10)

```

This graph shows that we need a sample size of approximately 58 to reach a power of 80% with the given population estimates. 

# A simulation-based power analysis for a mediation model with latent variables

Sometimes, researchers not only wish to investigate whether two (latent) variables related to each other, but rather whether the association between two (manifest or latent) variables is mediated by a third variable.


# References

Bergh, R., Akrami, N., Sidanius, J., & Sibley, C. G. (2016). Is group membership necessary for understanding generalized prejudice? A re-evaluation of why prejudices are interrelated. Journal of Personality and Social Psychology, 111(3), 367–395. https://doi.org/10.1037/pspi0000064

Wang, Y. A., & Rhemtulla, M. (2021). Power analysis for parameter estimation in structural equation modeling: A discussion and tutorial. Advances in Methods and Practices in Psychological Science, 4(1), 1–17. https://doi.org/10.1177/2515245920918253

